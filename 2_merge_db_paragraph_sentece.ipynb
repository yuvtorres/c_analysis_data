{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congressional Speech Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# its necessary to run --> pip3 install xlrd==1.2.0               \n",
    "df_charisma_analysis=pd.read_excel(\"charisma_analisis_complete_df.xlsx\", header=0)\n",
    "df_congress_114_bills=pd.read_excel(\"congress_114_bills_df_new.xlsx\",header=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2. Cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1 Indices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For df_congress_114_bills the field sentence_id has 0 repeted values\n",
      "\n",
      "While for df_charisma_analysis the field paragraph_id has 24 repeted index\n"
     ]
    }
   ],
   "source": [
    "print(f'''For df_congress_114_bills the field sentence_id has {sum(df_congress_114_bills.sentence_id.value_counts()>1)} repeted values\\n''')\n",
    "print(f'''While for df_charisma_analysis the field paragraph_id has {sum(df_charisma_analysis.paragraph_id.value_counts()==2)} repeted index''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3. Following sugestions\n",
    "\n",
    "##### 1 - Merging the bills dataframe and the complete dataframe of scored paragraphs by the unique_speech_id column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unique_speech_id column in df_charisma_analysis has \n",
      "     8353 rows repeated\n",
      "     That is 76% of the rows repeated\n",
      "\n",
      "The unique_speech_id column in df_congress_114_bills has \n",
      "     2278 rows repeated\n",
      "     That is 59% of the rows repeated\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'''The unique_speech_id column in df_charisma_analysis has \n",
    "     {sum(df_charisma_analysis.unique_speech_id.value_counts()[df_charisma_analysis.unique_speech_id.value_counts()>1])} rows repeated''')\n",
    "print(f'''     That is {sum(df_charisma_analysis.unique_speech_id.value_counts()[df_charisma_analysis.unique_speech_id.value_counts()>1])/df_charisma_analysis.shape[0]:.0%} of the rows repeated\\n''')\n",
    "\n",
    "print(f'''The unique_speech_id column in df_congress_114_bills has \n",
    "     {sum(df_congress_114_bills.unique_speech_id.value_counts()[df_congress_114_bills.unique_speech_id.value_counts()>1])} rows repeated''')\n",
    "\n",
    "print(f'''     That is {sum(df_congress_114_bills.unique_speech_id.value_counts()[df_congress_114_bills.unique_speech_id.value_counts()>1])/df_congress_114_bills.shape[0]:.0%} of the rows repeated\\n''')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we merge the data using **unique_spech_id** the result will be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A data base with 1005 rows, where the unique_speech_id has 972 rows repeted\n"
     ]
    }
   ],
   "source": [
    "df_merge_1=pd.merge(df_congress_114_bills, df_charisma_analysis,on='unique_speech_id')\n",
    "print(f'''A data base with {df_merge_1.shape[0]} rows, where the unique_speech_id has {sum(df_merge_1.unique_speech_id.value_counts()[df_merge_1.unique_speech_id.value_counts()>1])} rows repeted''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2 - Merging the bills dataframe and the complete dataframe of scored paragraphs by the document_id and speech_id columns simultaneously "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of **df_congress_114_bills** the index created by *document_id* and *speech_id*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "produce 2278 rows repeated of 3886 \n"
     ]
    }
   ],
   "source": [
    "ind_1= df_congress_114_bills.document_id.astype(str)+'-'+df_congress_114_bills.speech_id.astype(str)\n",
    "print(f'''produce {sum(ind_1.value_counts()[ind_1.value_counts()>1])} rows repeated of {df_congress_114_bills.shape[0]} ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of **df_charisma_analysis** the index created by *document_id* and *speech_id*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "produce 8353 rows repeated of 10938 \n"
     ]
    }
   ],
   "source": [
    "ind_2= df_charisma_analysis.document_id.astype(str)+'-'+df_charisma_analysis.speech_id.astype(str)\n",
    "print(f'''produce {sum(ind_2.value_counts()[ind_2.value_counts()>1])} rows repeated of {df_charisma_analysis.shape[0]} ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the two indexes cross:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 123 elements of df_congres_114_bills index_adhoc in df_charisma_analysis\n"
     ]
    }
   ],
   "source": [
    "ind_l1=set(ind_1.values)\n",
    "ind_l2=set(ind_2.values)\n",
    "print(f'''There are {sum([ a in ind_l2 for a in ind_l1])} elements of df_congres_114_bills index_adhoc in df_charisma_analysis''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A data base with 1005 rows, where the index_adhoc has 972 rows repeted\n"
     ]
    }
   ],
   "source": [
    "# generating the merging database:\n",
    "df_congress_114_bills['index_adhoc']= df_congress_114_bills.document_id.astype(str)+'-'+df_congress_114_bills.speech_id.astype(str)\n",
    "df_charisma_analysis['index_adhoc']= df_charisma_analysis.document_id.astype(str)+'-'+df_charisma_analysis.speech_id.astype(str)\n",
    "df_merge_2=pd.merge(df_congress_114_bills,df_charisma_analysis, on='index_adhoc')\n",
    "print(f'''A data base with {df_merge_2.shape[0]} rows, where the index_adhoc has {sum(df_merge_2.index_adhoc.value_counts()[df_merge_2.index_adhoc.value_counts()>1])} rows repeted''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3 - Try looking only at the document_id and check that the same document_id exists in both the paragraphs and the sentences dataframes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document_id from db_congress_114 in db_charisma \n",
      "      1970 \n",
      "      of which 273 are unique\n"
     ]
    }
   ],
   "source": [
    "doc_id_congress=[doc for doc in df_congress_114_bills.document_id.values] # creating list of doc_id from db_congress\n",
    "doc_id_db_congress_in_db_charisma=[df_charisma_analysis[df_charisma_analysis.document_id==ele].shape[0] for ele in doc_id_congress]\n",
    "doc_id_db_congress_in_db_charisma=pd.Series(data=doc_id_db_congress_in_db_charisma)\n",
    "doc_id_db_congress_in_db_charisma.value_counts().sum\n",
    "\n",
    "print(f'''document_id from db_congress_114 in db_charisma \n",
    "      {len(doc_id_db_congress_in_db_charisma)-doc_id_db_congress_in_db_charisma.value_counts()[0]} \n",
    "      of which {doc_id_db_congress_in_db_charisma.value_counts()[1]} are unique''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document_id from db_charisma in db_congress_114 \n",
      "      2976 \n",
      "      of which 956 are unique\n"
     ]
    }
   ],
   "source": [
    "doc_id_charisma=[doc for doc in df_charisma_analysis.document_id.values] # creating list of doc_id from db_congress\n",
    "doc_id_db_charisma_in_db_congress=[df_congress_114_bills[df_congress_114_bills.document_id==ele].shape[0] for ele in doc_id_charisma]\n",
    "doc_id_db_charisma_in_db_congress=pd.Series(data=doc_id_db_charisma_in_db_congress)\n",
    "doc_id_db_charisma_in_db_congress.value_counts().sum\n",
    "\n",
    "print(f'''document_id from db_charisma in db_congress_114 \n",
    "      {len(doc_id_db_charisma_in_db_congress)-doc_id_db_charisma_in_db_congress.value_counts()[0]} \n",
    "      of which {doc_id_db_charisma_in_db_congress.value_counts()[1]} are unique''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_3=pd.merge(df_charisma_analysis,df_congress_114_bills,on='document_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23053, 201)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge_3.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
