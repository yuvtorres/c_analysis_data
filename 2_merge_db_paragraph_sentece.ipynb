{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congressional Speech Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "charisma_analisis_complete has 10938 Rows, and 175 Columns\n",
      "congress_114_bills has 3886 Rows, and 25 Columns\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# its necessary to run --> pip3 install xlrd==1.2.0               \n",
    "df_charisma_analysis=pd.read_excel(\"charisma_analisis_complete_df.xlsx\", header=0)\n",
    "df_congress_114_bills=pd.read_excel(\"congress_114_bills_df_new.xlsx\",header=0)\n",
    "print(f'''charisma_analisis_complete has {df_charisma_analysis.shape[0]} Rows, and {df_charisma_analysis.shape[1]} Columns''')\n",
    "print(f'''congress_114_bills has {df_congress_114_bills.shape[0]} Rows, and {df_congress_114_bills.shape[1]} Columns''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2. Cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1 Indices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For df_congress_114_bills the field sentence_id has 0 repeted values\n",
      "\n",
      "While for df_charisma_analysis the field paragraph_id has 24 repeted index\n"
     ]
    }
   ],
   "source": [
    "print(f'''For df_congress_114_bills the field sentence_id has {sum(df_congress_114_bills.sentence_id.value_counts()>1)} repeted values\\n''')\n",
    "print(f'''While for df_charisma_analysis the field paragraph_id has {sum(df_charisma_analysis.paragraph_id.value_counts()==2)} repeted index''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2 Repeted paragraph_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The list of repeated id_paragraph is:\n",
      "7492    2\n",
      "3015    2\n",
      "38      2\n",
      "9841    2\n",
      "5902    2\n",
      "4910    2\n",
      "6420    2\n",
      "6950    2\n",
      "8505    2\n",
      "2693    2\n",
      "7640    2\n",
      "6911    2\n",
      "9637    2\n",
      "6788    2\n",
      "6391    2\n",
      "2851    2\n",
      "3010    2\n",
      "7990    2\n",
      "4490    2\n",
      "5219    2\n",
      "5415    2\n",
      "4858    2\n",
      "1713    2\n",
      "6621    2\n",
      "Name: paragraph_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('The list of id_paragraph repeated is:')\n",
    "print(df_charisma_analysis.paragraph_id.value_counts()[df_charisma_analysis.paragraph_id.value_counts()>1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The differences between this rows are in the features values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>unique_speech_id</th>\n",
       "      <th>paragraph_len</th>\n",
       "      <th>document_id</th>\n",
       "      <th>speech_id</th>\n",
       "      <th>clean_speaker_name</th>\n",
       "      <th>prefix</th>\n",
       "      <th>document_title</th>\n",
       "      <th>hearing_date</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_111</th>\n",
       "      <th>feature_112</th>\n",
       "      <th>feature_113</th>\n",
       "      <th>feature_114</th>\n",
       "      <th>feature_115</th>\n",
       "      <th>feature_116</th>\n",
       "      <th>feature_117</th>\n",
       "      <th>feature_118</th>\n",
       "      <th>feature_119</th>\n",
       "      <th>ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10608</th>\n",
       "      <td>7492</td>\n",
       "      <td>He said,  let's take an overall look at what w...</td>\n",
       "      <td>149789</td>\n",
       "      <td>114</td>\n",
       "      <td>1367</td>\n",
       "      <td>604</td>\n",
       "      <td>Price, Tom</td>\n",
       "      <td>mr.</td>\n",
       "      <td>military construction, veterans affairs, and r...</td>\n",
       "      <td>february 26, 2016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155191</td>\n",
       "      <td>0.078706</td>\n",
       "      <td>-0.000069</td>\n",
       "      <td>-0.024627</td>\n",
       "      <td>-0.207416</td>\n",
       "      <td>-0.084438</td>\n",
       "      <td>0.22280</td>\n",
       "      <td>-0.149085</td>\n",
       "      <td>-0.112272</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10609</th>\n",
       "      <td>7492</td>\n",
       "      <td>He said,  let's take an overall look at what w...</td>\n",
       "      <td>149789</td>\n",
       "      <td>114</td>\n",
       "      <td>1367</td>\n",
       "      <td>604</td>\n",
       "      <td>Price, Tom</td>\n",
       "      <td>mr.</td>\n",
       "      <td>military construction, veterans affairs, and r...</td>\n",
       "      <td>february 26, 2016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155229</td>\n",
       "      <td>0.076456</td>\n",
       "      <td>0.023945</td>\n",
       "      <td>-0.036282</td>\n",
       "      <td>-0.167618</td>\n",
       "      <td>-0.094304</td>\n",
       "      <td>0.23413</td>\n",
       "      <td>-0.165397</td>\n",
       "      <td>-0.164193</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       paragraph_id                                          paragraph  \\\n",
       "10608          7492  He said,  let's take an overall look at what w...   \n",
       "10609          7492  He said,  let's take an overall look at what w...   \n",
       "\n",
       "       unique_speech_id  paragraph_len  document_id  speech_id  \\\n",
       "10608            149789            114         1367        604   \n",
       "10609            149789            114         1367        604   \n",
       "\n",
       "      clean_speaker_name prefix  \\\n",
       "10608         Price, Tom    mr.   \n",
       "10609         Price, Tom    mr.   \n",
       "\n",
       "                                          document_title       hearing_date  \\\n",
       "10608  military construction, veterans affairs, and r...  february 26, 2016   \n",
       "10609  military construction, veterans affairs, and r...  february 26, 2016   \n",
       "\n",
       "       ... feature_111  feature_112 feature_113 feature_114 feature_115  \\\n",
       "10608  ...    0.155191     0.078706   -0.000069   -0.024627   -0.207416   \n",
       "10609  ...    0.155229     0.076456    0.023945   -0.036282   -0.167618   \n",
       "\n",
       "      feature_116  feature_117 feature_118 feature_119    ind  \n",
       "10608   -0.084438      0.22280   -0.149085   -0.112272  train  \n",
       "10609   -0.094304      0.23413   -0.165397   -0.164193  train  \n",
       "\n",
       "[2 rows x 175 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_charisma_analysis.loc[df_charisma_analysis.paragraph_id==7492]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3. Following sugestions\n",
    "\n",
    "##### 1 - Merging the bills dataframe and the complete dataframe of scored paragraphs by the unique_speech_id column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unique_speech_id column in df_charisma_analysis has \n",
      "     8353 rows repeated\n",
      "     That is 76% of the rows repeated\n",
      "\n",
      "The unique_speech_id column in df_congress_114_bills has \n",
      "     2278 rows repeated\n",
      "     That is 59% of the rows repeated\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'''The unique_speech_id column in df_charisma_analysis has \n",
    "     {sum(df_charisma_analysis.unique_speech_id.value_counts()[df_charisma_analysis.unique_speech_id.value_counts()>1])} rows repeated''')\n",
    "print(f'''     That is {sum(df_charisma_analysis.unique_speech_id.value_counts()[df_charisma_analysis.unique_speech_id.value_counts()>1])/df_charisma_analysis.shape[0]:.0%} of the rows repeated\\n''')\n",
    "\n",
    "print(f'''The unique_speech_id column in df_congress_114_bills has \n",
    "     {sum(df_congress_114_bills.unique_speech_id.value_counts()[df_congress_114_bills.unique_speech_id.value_counts()>1])} rows repeated''')\n",
    "\n",
    "print(f'''     That is {sum(df_congress_114_bills.unique_speech_id.value_counts()[df_congress_114_bills.unique_speech_id.value_counts()>1])/df_congress_114_bills.shape[0]:.0%} of the rows repeated\\n''')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we merge the data using **unique_spech_id** the result will be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A data base with 1005 rows, where the unique_speech_id has 972 rows repeted\n"
     ]
    }
   ],
   "source": [
    "df_merge_1=pd.merge(df_congress_114_bills, df_charisma_analysis,on='unique_speech_id')\n",
    "print(f'''A data base with {df_merge_1.shape[0]} rows, where the unique_speech_id has {sum(df_merge_1.unique_speech_id.value_counts()[df_merge_1.unique_speech_id.value_counts()>1])} rows repeted''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2 - Merging the bills dataframe and the complete dataframe of scored paragraphs by the document_id and speech_id columns simultaneously "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of **df_congress_114_bills** the index created by *document_id* and *speech_id*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "produce 2278 rows repeated of 3886 \n"
     ]
    }
   ],
   "source": [
    "ind_1= df_congress_114_bills.document_id.astype(str)+'-'+df_congress_114_bills.speech_id.astype(str)\n",
    "print(f'''produce {sum(ind_1.value_counts()[ind_1.value_counts()>1])} rows repeated of {df_congress_114_bills.shape[0]} ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of **df_charisma_analysis** the index created by *document_id* and *speech_id*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "produce 8353 rows repeated of 10938 \n"
     ]
    }
   ],
   "source": [
    "ind_2= df_charisma_analysis.document_id.astype(str)+'-'+df_charisma_analysis.speech_id.astype(str)\n",
    "print(f'''produce {sum(ind_2.value_counts()[ind_2.value_counts()>1])} rows repeated of {df_charisma_analysis.shape[0]} ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the two indexes cross:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 123 elements of df_congres_114_bills index_adhoc in df_charisma_analysis\n"
     ]
    }
   ],
   "source": [
    "ind_l1=set(ind_1.values)\n",
    "ind_l2=set(ind_2.values)\n",
    "print(f'''There are {sum([ a in ind_l2 for a in ind_l1])} elements of df_congres_114_bills index_adhoc in df_charisma_analysis''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A data base with 1005 rows, where the index_adhoc has 972 rows repeted\n"
     ]
    }
   ],
   "source": [
    "# generating the merging database:\n",
    "df_congress_114_bills['index_adhoc']= df_congress_114_bills.document_id.astype(str)+'-'+df_congress_114_bills.speech_id.astype(str)\n",
    "df_charisma_analysis['index_adhoc']= df_charisma_analysis.document_id.astype(str)+'-'+df_charisma_analysis.speech_id.astype(str)\n",
    "df_merge_2=pd.merge(df_congress_114_bills,df_charisma_analysis, on='index_adhoc')\n",
    "print(f'''A data base with {df_merge_2.shape[0]} rows, where the index_adhoc has {sum(df_merge_2.index_adhoc.value_counts()[df_merge_2.index_adhoc.value_counts()>1])} rows repeted''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3 - Try looking only at the document_id and check that the same document_id exists in both the paragraphs and the sentences dataframes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  \n",
      "      1970\n",
      "      document_id from db_congress_114 in db_charisma\n",
      "      of which 273 are unique\n"
     ]
    }
   ],
   "source": [
    "doc_id_congress=[doc for doc in df_congress_114_bills.document_id.values] # creating list of doc_id from db_congress\n",
    "doc_id_db_congress_in_db_charisma=[df_charisma_analysis[df_charisma_analysis.document_id==ele].shape[0] for ele in doc_id_congress]\n",
    "doc_id_db_congress_in_db_charisma=pd.Series(data=doc_id_db_congress_in_db_charisma)\n",
    "doc_id_db_congress_in_db_charisma.value_counts().sum\n",
    "\n",
    "print(f'''There are  \n",
    "      {len(doc_id_db_congress_in_db_charisma)-doc_id_db_congress_in_db_charisma.value_counts()[0]}\n",
    "      document_id from db_congress_114 in db_charisma\n",
    "      of which {doc_id_db_congress_in_db_charisma.value_counts()[1]} are unique''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  \n",
      "      2976 \n",
      "      document_id from db_charisma in db_congress_114\n",
      "      of which 956 are unique\n"
     ]
    }
   ],
   "source": [
    "doc_id_charisma=[doc for doc in df_charisma_analysis.document_id.values] # creating list of doc_id from db_congress\n",
    "doc_id_db_charisma_in_db_congress=[df_congress_114_bills[df_congress_114_bills.document_id==ele].shape[0] for ele in doc_id_charisma]\n",
    "doc_id_db_charisma_in_db_congress=pd.Series(data=doc_id_db_charisma_in_db_congress)\n",
    "doc_id_db_charisma_in_db_congress.value_counts().sum\n",
    "\n",
    "print(f'''There are  \n",
    "      {len(doc_id_db_charisma_in_db_congress)-doc_id_db_charisma_in_db_congress.value_counts()[0]} \n",
    "      document_id from db_charisma in db_congress_114\n",
    "      of which {doc_id_db_charisma_in_db_congress.value_counts()[1]} are unique''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> I don't see too much sense to continue with this suggestion because of the quantities of not unique in both db will mix the information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23053, 199)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge_3=pd.merge(df_charisma_analysis,df_congress_114_bills,on='document_id')\n",
    "df_merge_3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. New key "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> attribute sentences to the corresponding paragraphs. Both datasets refer to a series of documents which are identified by the column \"name\" which is the same in both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.txt     293\n",
       "1.txt      259\n",
       "21.txt     240\n",
       "47.txt     215\n",
       "39.txt     212\n",
       "          ... \n",
       "119.txt      2\n",
       "107.txt      2\n",
       "187.txt      1\n",
       "110.txt      1\n",
       "99.txt       1\n",
       "Name: name, Length: 195, dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_charisma_analysis.name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.txt     123\n",
       "41.txt     112\n",
       "4.txt      110\n",
       "7.txt      102\n",
       "51.txt      98\n",
       "          ... \n",
       "183.txt      1\n",
       "110.txt      1\n",
       "125.txt      1\n",
       "164.txt      1\n",
       "176.txt      1\n",
       "Name: name, Length: 167, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_congress_114_bills.name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.txt     32816\n",
       "24.txt     24723\n",
       "4.txt      19690\n",
       "39.txt     18868\n",
       "1.txt      17353\n",
       "           ...  \n",
       "140.txt        6\n",
       "181.txt        5\n",
       "145.txt        3\n",
       "192.txt        2\n",
       "110.txt        1\n",
       "Name: name, Length: 151, dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge_4=pd.merge(df_congress_114_bills,df_charisma_analysis, on='name')\n",
    "df_merge_4.name.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> There are more *name* 195 in *charisma_analysis* than in *congress_114_bills* 167. Moreover, in common they only have 151!\n",
    "\n",
    "So, there are **16** *name* in *congress_114_bills* not in *charisma_analysis*, and **44** *name* in *charisma_analysis* not in *congress_114_bills*."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
